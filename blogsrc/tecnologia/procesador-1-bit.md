---
title: "Procesador de 1 bit de ancho de palabra"
date: "2022-06-02"
categories: ["Tecnolog√≠a"]
language: "es-ES"
---
¬øPor qu√© un bit de ancho? Pues los elementos constituyentes de un ordenador son los mismos cualquiera que sea el ancho de palabra. El conjunto o set de instrucciones es, obviamente, m√°s breve dado que no se pueden hacer tantas operaciones: con un solo bit no hay diferencia entre operaciones ‚Äòbit a bit‚Äô (*bitwise*) y ‚Äòl√≥gicas‚Äô (*logical*), como habitualmente se las conoce, y sumar es lo mismo que hacer un or exclusivo (`XOR`) si ignoramos el resto y multiplicar es lo mismo que hacer un `AND`, as√≠ que las instrucciones son menos, pero sigue habiendo, usando las abreviaturas habituales en la industria, `LOAD`, `SAVE`, `AND`, `OR`, `NOT`, `XOR` y saltos condicionales o no. Tambi√©n tiene un puntero al paso de programa y podr√≠a tener una pila o *stack* para llamar subrutinas y volver.

----

Si nos ponemos en te√≥ricos, la m√°quina de Turing era de un bit de ancho de palabra y su importancia estriba en que con ella Alan Turing demuestra que toda m√°quina de Turing puede emular a otra m√°quina de Turing, con m√°s o menos esfuerzo. Por lo tanto un chip de un bit de ancho de palabra no es tan extra√±o a fines te√≥ricos/did√°cticos. La m√°quina de Turing ten√≠a una cinta (su memoria) infinita y un procesador de un bit tambi√©n requerir√≠a much√≠simos bits de memoria para resolver cualquier operaci√≥n de una de mayor ancho de palabra, pero la teor√≠a dice que es posible.

Por ejemplo, sumar dos posiciones de memoria de 8 bits puede hacerse en un solo ciclo en un procesador de 8 bits o en 8 ciclos en uno de un bit, de a un bit a la vez. En realidad se necesitan 16 ciclos para llevar el resto y muchos m√°s si se va a controlar si el resultado es cero, o si una resta es negativa o si ha habido overflow, cosa que cualquier procesador de 8 bits hace en paralelo con la suma en s√≠. De todas maneras estas comprobaciones que se hacen autom√°ticamente en un chip multi-bit no se usan siempre, la mayor parte de las veces se ignoran. Habitualmente se usan junto con instrucciones de salto condicional: `JZ` (*Jump if Zero*), `JC` (*Jump if Carry*), `JN` (*Jump if Negative*), `JV` (*Jump if oVerflow*) y sus opuestas: `JNZ` (*Jump of Not Zero*) y dem√°s negaciones de las primeras. En el caso de un procesador de 1 bit emulando uno de mayor ancho de palabra, valdr√≠a la pena postergar el c√°lculo de los bits de estado hasta que la presencia de la instrucci√≥n de salto condicional lo requiriera. En otras palabras, que los procesadores multi-bit calculen estos bits autom√°ticamente es una optimizaci√≥n que pueden hacer a costo nulo, pero si ello demandara ciclos de ejecuci√≥n, bien puede omitirse y hacerlas bajo demanda.

Fuera de la teor√≠a, tiempo ha exist√≠a un micro-controlador de un bit de ancho de palabra, un simple chip de 20 o 22 patitas. Si ese chip exist√≠a y se comercializaba, ser√° porque serv√≠a para algo. A fin de cuentas controlar un ascensor no necesita m√°s, de hecho, en aquella √©poca se hac√≠a con simples rel√©s electromec√°nicos, que son de un s√≥lo bit con l√≥gica cableada (*hard-wired*).

## ALU

El caso es que la ALU (por las siglas en ingl√©s de Unidad Aritm√©tica y L√≥gica) o, en este caso, LU dado que no har√≠a aritm√©tica, se podr√≠a componer simplemente de 4 compuertas, `AND`, `OR`, `XOR` y `NOT`. Todas ellas procesar√≠an en paralelo el mismo par de valores (excepto la `NOT` que procesa un s√≥lo valor) y se generar√≠an los 4 posibles resultados. Una compuerta a la salida de cada una de ellas se activar√≠a para dejar pasar el resultado que se busca. Esto, b√°sicamente, formar√≠a la (A)LU que, normalmente, se representa como una Y griega con dos entradas y una √∫nica salida,como un embudo, con una flecha lateral que indica las l√≠neas de control que seleccionan la operaci√≥n. Las cuatro salidas se alimentan a un multiplexor que es un circuito que selecciona uno de 4 valores de entrada en funci√≥n de dos l√≠neas de control, por ejemplo, el [74x153](https://www.ti.com/lit/ds/symlink/sn74ls153.pdf).

<figure>
<img src="assets/img/alu.webp" title="ALU" />
<figcaption>
Los bits A y B se combinan en la primera fila de compuertas obteniendo `A AND B`, `A OR B`, `A XOR B` y `NOT B`. Luego, seg√∫n que l√≠nea S est√© activa, el resultado de una de estas operaciones llega a R
</figcaption>
</figure>

Los bits A y B se combinan en la primera fila de compuertas obteniendo `A AND B`, `A OR B`, `A XOR B` y `NOT B`. Luego, seg√∫n cu√°l l√≠nea S est√© activa, el resultado de una de estas operaciones llega a R. Las dos filas inferiores pueden reemplazarse por un chip como el [74x153](https://www.ti.com/lit/ds/symlink/sn74ls153.pdf)

Seg√∫n la arquitectura del chip hay dos opciones extremas para las dos entradas de la Y y la salida. La m√°s flexible es leer los dos valores a procesar de sendas posiciones de memoria y volcar el resultado en otra posici√≥n de memoria. Eso implica poner multiplexores/demultiplexores en cada uno de los brazos de la Y para seleccionar independientemente las entradas y la salida. Si se tienen 256 posiciones de memoria, se necesitan 8 bits para seleccionar cada posici√≥n y en este esquema, con selecci√≥n independiente de 3 posiciones de memoria, implicar√≠a usar 24 pines nada m√°s que para seleccionar el origen de los operandos y el destino del resultado. Acabar√≠amos con m√°s pines que silicio.

Lo m√°s pr√°ctico suele ser predeterminar parte de estas direcciones. De all√≠ surge lo que se conoce como el ‚Äòacumulador‚Äô, que es una celda de memoria interna dentro de la CPU que es el origen predeterminado de uno de los dos operandos y es el destino predeterminado del resultado. Este es el otro extremo del espectro.

<figure>
<img src="assets/img/acumulador.webp" title="Acumulador" />
<figcaption>
A la izquierda una ALU que recibe datos de cualquier posible posici√≥n de memoria A y B y env√≠a al resultado R a cualquier posible posici√≥n de memoria. A la derecha, una ALU con un acumulador ACC que es siempre el destino del resultado y el origen de uno de sus operandos mientras el otro puede venir de cualquier posici√≥n de memoria M. La primera requiere muchas m√°s l√≠neas de datos conectando la ALU con memoria que la segunda.
</figcaption>
</figure>

¬øD√≥nde est√° la ventaja de usar un acumulador si nos obliga, primero, a que cargar uno de los operandos en el acumulador, hacer la operaci√≥n con el segundo operando y, si el resultado ha de ir a memoria, guardar el resultado en el destino final? El caso es que lo m√°s frecuente es que se encadenen varias operaciones sobre los mismos valores por lo que, en realidad, las m√°s de las veces se sigue operando con el acumulador. Dada la poca variedad de operaciones que se pueden hacer con un bit, esto no es tan probable, pero habiendo m√°s operaciones disponibles, las probabilidades de reutilizar el acumulador en una misma secuencia aumentan.

## Set de instrucciones

Entonces, tenemos 8 operaciones posibles, que se pueden codificar muy sencillamente en 3 bits que llamaremos por sus abreviaturas habituales en algunos lenguajes ensambladores (*assembler*): `AND`, `OR`, `XOR`, `NOT`, `LOAD`, `SAVE`, `JMP` (*JuMP*, incondicional), `JT` (*Jump if True*).

Cada una de estas instrucciones va seguida de una direcci√≥n de memoria, ya sea para el operando que no es el acumulador, que est√° impl√≠cito, ya sea para indicar donde se encuentra el valor a cargar o donde guardar el resultado, o para indicar la direcci√≥n a donde se ha de saltar (excepto el `NOT` que no tiene segundo operando).

Las posiciones de memoria, en nuestro procesador de un bit, pueden no estar realmente en un chip de memoria sino ser dispositivos binarios a manipular tales como pulsadores de llamada de un ascensor, sensores de ubicaci√≥n de la cabina en cada piso, control del motor y el freno y accionamiento de puertas y s√≠, tambi√©n algo de memoria para memorizar las llamadas de los varios pisos y tambi√©n para recordar en qu√© direcci√≥n estaba yendo.

## Registros internos

Aqu√≠ podemos seguir un paso m√°s en el dise√±o de nuestra CPU y optar por disponer de registros internos, esto es, posiciones de trabajo internas dentro del mismo chip del procesador. Ya hemos hablado del acumulador como una posici√≥n de memoria dentro del procesador. Podemos tener m√°s de estas posiciones de trabajo. ¬øCu√°l es la ventaja? Por un lado, estando dentro del chip son m√°s r√°pidas de acceder. Toda vez que una se√±al sale del chip hay un retardo. La velocidad de la luz es de unos 30cm por nanosegundo y, a la velocidad del procesador, cualquier cosa que est√© fuera del chip est√° lejos (hay razones el√©ctricas tambi√©n, pero no vienen al caso).

En segundo lugar, los registros tambi√©n nos ofrecen m√°s casillas de trabajo en que guardar resultados intermedios y encadenar secuencias de operaciones. Adem√°s, al haber menos registros que memoria, se puede referir a cualquier registro con muchos menos bits que una posici√≥n de memoria. Por ejemplo, podemos tener 16 registros de trabajo y usar 4 bits de direcci√≥n de registro. Habiendo registros, podemos establecer que todas las operaciones se hacen entre un registro y el acumulador con el resultado en otro registro, siendo el acumulador el registro 0.

Nuestro set de instrucciones puede convertirse en algo como se muestra en la siguiente tabla donde cada n√∫mero en las primeras tres columnas indican un bit seguido de 8 bits (representados por letras) para el/los operandos, seguidos de su mnem√≥nico y la explicaci√≥n:

<figure>
<img src="assets/img/setInstrucciones.webp" title="Set de Instrucciones" />
<figcaption>
Las primeras columnas, bajo el encabezado de C√≥digo binario representan bits individuales. Los fondos de colores sirven para destacar la regularidad en la interpretaci√≥n de los bits de cada grupo.
</figcaption>
</figure>

Como se puede ver, todas las instrucciones son de una √∫nica ‚Äòpalabra‚Äô de 11 bits de ancho (ya s√© que es un ancho de palabra extra√±o, pero tambi√©n lo es un procesador de un bit üòâ ). Es muy homog√©neo pues ya los primeros 3 bits, en amarillo, indican qu√© hacer.

Tenemos una primera subdivisi√≥n, si el primer bit est√° en cero, como en las 4 primeras filas, es una operaci√≥n que implica el acceso a memoria externa y los √∫ltimos 8 bits (`mmmmmmmm`) indican la direcci√≥n. Si el primer bit es 1, es una operaci√≥n entre registros siendo `ssss` y `dddd` los registros de origen y destino de la operaci√≥n.

Una segunda subdivisi√≥n nos da cuatro grupos de 2 instrucciones cada uno, a saber:

* `LOAD` y `SAVE` nos permite acceder a datos a memoria, con el tercer bit indicando la direcci√≥n (carga o graba).
* `JMP` y `JT` son saltos en la ejecuci√≥n del programa, con el tercer bit indicando si es condicional al estado del acumulador o no.
* `AND` y `OR` son las operaciones l√≥gicas b√°sicas entre un registro y el acumulador con el resultado en otro (o el mismo) registro.
* `MOVE` y `NOT`, copian un registro en otro donde el tercer bit nos dice si ha de invertirse en el proceso.

La regularidad en la interpretaci√≥n de cada bit dentro del c√≥digo de la instrucci√≥n es importante porque facilita su decodificaci√≥n y la activaci√≥n de los varios circuitos dentro de la CPU. Por ejemplo, ya comentamos que todas las operaciones fuera del chip necesitan m√°s tiempo en ejecutarse, por lo que ya el primer bit del c√≥digo de la instrucci√≥n nos dice si estirar el ciclo de ejecuci√≥n (usualmente el procesador deja pasar el siguiente tic del reloj) para darle tiempo al dato externo a llegar o ejecutarse de inmediato al ser una operaci√≥n interna, y tambi√©n permite saber c√≥mo interpretar los √∫ltimos 8 bits, si como una direcci√≥n de memoria absoluta de 8 bits o dos referencias a registros internos de trabajo de 4 bits cada una.

Es un set de instrucciones muy RISC (*Reduced Instruction Set Computer*). Instrucciones simples, todas de una sola palabra, codificando toda la informaci√≥n relevante de la forma m√°s regular posible. Esto es a diferencia de una CPU CISC (*Complex Instruction Set Computer*) donde se disponen de muchas m√°s instrucciones, algunas de ellas requiriendo m√∫ltiples palabras para completar toda la informaci√≥n que se necesita, obligando a un proceso de decodificaci√≥n mucho m√°s complejo. Por ejemplo los chips tipo ARM o RISC-V son RISC, la familia ix86 es CISC donde una instrucci√≥n puede llegar a 15 bytes de largo.

Aparentemente, en este set de instrucciones faltan cosas, por ejemplo no hay `JF` (*Jump if False*) pero este se puede codificar con la secuencia de un `NOT` seguido de un `JT`.

Hemos perdido la operaci√≥n `XOR` que aparec√≠a en el diagrama l√≥gico de la ALU de m√°s arriba. Ocurre que al disponer de registros, estamos obligados a proveer la capacidad de mover los datos de un registro a otro y al tener que agregar la instrucci√≥n `MOVE`, nos hemos visto obligados a hacer un hueco en las 8 posibles combinaciones de 3 bits de que disponemos, y por eso hemos dejado caer el `XOR` que, de todas formas, al igual que el JF, se puede reemplazar por una secuencia de operaciones l√≥gicas.

Nos falta alg√∫n mecanismo para poner un registro en cero o en uno. Para ello, no es inusual destinar un registro fantasma que siempre est√© en 0 (y potencialmente otro para que siempre est√© en uno). Digamos que el registro 15 (`1111`) est√° siempre en 0 y el 14 (1110) en 1. Poner en cero el registro `xxxx` se hace con `MOVE 15, xxxx`. Siempre se trata de mantener cierta regularidad en la circuiter√≠a, por ejemplo, los dos registros falsos comienzan con `111`.

Y, como en toda decisi√≥n de ingenier√≠a, hay que buscar un compromiso. ¬øQu√© opci√≥n podr√° dar mejor provecho? ¬øVale m√°s, destinar dos registros fantasmas a guardar 0 y 1 o tener un solo registro falso con 0 y obtener el 1 negando un 0 en la instrucci√≥n siguiente? Lo segundo es mejor pues, disponer del cero es indispensable, mientras que el 1 se puede generar, cuando se quiera.

Un procesador CISC dispondr√≠a de las operaciones `JF` y `XOR`, un RISC deja a cargo del compilador o ensamblador reemplazarlo con su equivalente si fuera necesario.

## Macro-ensamblador

Hasta ahora, apenas nos hemos referido a la representaci√≥n de las operaciones de la CPU usando sus valores binarios, bit a bit, en el cuadro m√°s arriba. Es raro programar usando binario. A√∫n al nivel m√°s b√°sico, se utiliza un ensamblador (*assembler*) que traduce mnem√≥nicos como `ADD` o `MOVE` y que tambi√©n nos permite usar n√∫meros decimales (o cualquier otra base) en lugar de binarios o hacer referencia a posiciones del c√≥digo con nombres para usar en `JMP` o `JT`.

El macro-ensamblador (*macro-assembler*) agrega la facilidad de crear aliases ya sea para los operandos o los mnem√≥nicos o incluso a secuencias de ellos. Por ejemplo, en un macro-assembler se puede tener pre-definido `ACC = 0` para referirse al acumulador (que es nuestro registro 0) o `ZERO = 15` para el registro fantasma que contiene un cero. Tambi√©n podr√≠amos definir nuevos mnem√≥nicos, algunos que ya hemos visto, otros nuevos (en assembler, se usa el car√°cter `;` para indicar un comentario)

<pre><code class="language.asm">
    DEF ACC 0     ; definimos la constante ACC igual a 0

    DEF ZERO 15 

    MACRO JF dest ; macro-instrucci√≥n JF con un √∫nico argumento
    NOT ACC       ; Negar el acumulador usando la macro previa
    JT dest
    ENDMACRO

    MACRO RESET r  
    MOVE ZERO, r
    ENDMACRO

    MACRO SET r
    RESET r
    NOT r, r
    ENDMACRO
</code></pre>
Las pseudo-instrucciones `DEF`, `MACRO` y `ENDMACRO` no se traducen directamente en c√≥digos de operaci√≥n para la CPU sino que son declaraciones para el macro-assembler para ya sea *DEF*inir constantes o *MACRO*-instrucciones formadas por m√∫ltiples instrucciones y posiblemente operandos.

## Otros componentes

Adem√°s de la A(LU), y los 16 registros internos, entre ellos el acumulador y otro fantasma conteniendo un 0, la CPU ha de tener,

1. un registro de instrucci√≥n, en este caso, de 11 bits, que guarde la instrucci√≥n en curso mientras se est√° procesando.
2. un registro de paso de programa, en nuestro caso de 8 bits, donde se indica la posici√≥n de memoria de la pr√≥xima instrucci√≥n a ser ejecutada y que se incrementa autom√°ticamente tras cargar cada instrucci√≥n en el registro de instrucci√≥n. Este habitualmente se abrevia como `PC` por *Program Counter*.

Por ejemplo, si los 3 primeros bits del registro de instrucci√≥n son son `010` (`JMP`) quiere decir que los √∫ltimos 8 bits del registro de instrucci√≥n se deben copiar en el `PC`, para que la ejecuci√≥n del programa contin√∫e en dicha direcci√≥n. Si la instrucci√≥n comienza con `011` (`JT`), la copia se hace condicional a que el acumulador est√© en 1.

Si los dos primeros bits del registro de instrucci√≥n son `00` (`LOAD` y `SAVE`), entonces los √∫ltimos 8 bits se deben exponer en el bus de direcciones para seleccionar la posici√≥n de memoria y el tercer bit dice si esa posici√≥n se ha de leer o grabar.

## Eficiencia.

Cada circuito que se agrega implica una demora. Ya en la primera p√°gina del demultiplexor [74153](https://www.ti.com/lit/ds/symlink/sn74ls153.pdf) que se√±al√© m√°s arriba se ofrece el dato de ‚Äútypical average propagation delay times‚Äù lo que resalta su importancia. El problema con sumar mucha circuiter√≠a es que estas demoras de propagaci√≥n se van sumando y hacen al procesador m√°s lento. Una soluci√≥n es describir el circuito como ecuaciones Booleanas y simplificarlas como cualquier operaci√≥n algebraica.

Sabemos que, en aritm√©tica normal la ecuaci√≥n `(a + -b * c) * d` podemos simplificarla como `a * -b * d + a * c * d`. La ventaja de esta √∫ltima representaci√≥n es que podemos procesar los dos t√©rminos `(a * -b * d)` y `(a * c * d)` en paralelo y luego sumarlos entre si mientras que en la primera ecuaci√≥n, tenemos que esperar el resultado de `(-b * c)` para reci√©n sumarlo a la `a` para finalmente multiplicarlo por `d`, agregando un paso a la otra alternativa. En circuitos digitales eso de ‚Äòesperar‚Äô no es bueno. Entonces en lugar de encadenar ‚Äòbloques funcionales‚Äô que en la pr√°ctica son compuertas de diversos tipos compuestas a su vez de varias cadenas de otros circuitos conectados en serie unos detr√°s de otros, podemos simplificar la ecuaci√≥n l√≥gica de buena parte del circuito para hacer m√°s cosas en paralelo y reducir la demora a no m√°s de dos o tres ‚Äúpropagation delay times‚Äù.

Viendo el diagrama l√≥gico interno del demultiplexor [74x153](https://www.ti.com/lit/ds/symlink/sn74ls153.pdf), al pie de la segunda p√°gina observamos el efecto de esta simplificaci√≥n de las ecuaciones l√≥gicas, algo que se puede aplicar a muchos circuitos l√≥gicos. Todos se pueden reducir a tres pasos:

1. Negar todas las entradas.
   Con esto se ofrece en las barras verticales, todas las se√±ales de entrada y sus opuestos.
2. El `AND` de las se√±ales que se quieran de estas barras verticales
   (todos estos resultados se podr√≠an tambi√©n conectar a una segunda serie de barras verticales)
3. El `OR` de las salidas de los `AND` para obtener el resultado

Entre las etapas 2. y 3. podr√≠a haberse dispuesto otro grupo de barras verticales con todos los `AND`, pero reagrupando apropiadamente las compuertas, el delineante lo ha evitado. Tampoco es necesario m√°s compuertas inversoras intermedias dado que `NOT (a AND b)` es igual a `(NOT a OR NOT b)`, o sea que haciendo todas las negaciones al inicio, se cubren todas las posibilidades. (Nota: el circuito muestra algunas compuertas inversoras extra al inicio, pero estas est√°n all√≠ por consideraciones el√©ctricas, no de la l√≥gica del circuito).

## Clock

La diferencia en los tiempos de propagaci√≥n de las se√±ales es la raz√≥n para el clock que usan las CPUs y por qu√© este afecta la eficiencia del procesador. El caso es que dados estos varios tiempos de propagaci√≥n de los varios circuitos internos, hay momentos de inestabilidad mientras las se√±ales de unos circuitos llegan a los que le siguen en la cadena mientras los de otros todav√≠a est√°n al llegar. Esto quiere decir que hay momentos en que los datos no son confiables.

De hecho, hay operaciones que nunca podr√≠an ser estables, tal como un `NOT` de un registro sobre si mismo. Si originalmente fuera 0, el `NOT` producir√≠a un 1, pero como ahora ese registro contiene un 1, su `NOT` es 0, cuyo `NOT` es 1 y as√≠ siguiendo tan r√°pido como la demora en la propagaci√≥n del resultado lo permitiera.

Uno de los primeros ordenadores de uso acad√©mico en la Universidad de Buenos Aires se llamaba [Clementina](https://es.wikipedia.org/wiki/Clementina_(computadora)). El panel de control del operador ten√≠a un altavoz y el fabricante hab√≠a provisto, como muestra, un programa que hac√≠a sonar en este altavoz la canci√≥n *Oh my darling, Clementine*. De all√≠ surgi√≥ el nombre. La funci√≥n real de este altavoz era detectar si un programa hab√≠a entrado en bucle. Si una operaci√≥n tardaba demasiado (y dada la velocidad de procesamiento de aquella √©poca, todos los programas tardaban bastante) el operador pod√≠a subir el volumen de ese altavoz y, si sonaba un tono uniforme, hab√≠a entrado en bucle. Habitualmente emit√≠a ruido blanco.

Por ello, debemos interrumpir esta realimentaci√≥n para estabilizar el resultado una vez hecho el primer ciclo.

Es necesario disponer de ‚Äòlatches‚Äô (que se traduce como pestillo, aunque quiz√°s ser√≠a mejor llamarlo ‚Äòbarrera‚Äô o algo as√≠) como el [74100](https://pdf1.alldatasheet.es/datasheet-pdf/view/107803/TI/SN74100.html) que mantienen estable el valor de la operaci√≥n anterior y s√≥lo dejan pasar el valor de una nueva operaci√≥n cuando ha transcurrido la demora del camino de propagaci√≥n m√°s lento del circuito y por ello el nuevo dato est√° estable y es confiable, evitando as√≠ las inestabilidades en los momentos de transici√≥n.

Y para accionar estos latches se necesita el clock que vaya marcando los tiempos de espera para estas demoras. Suele haber dos etapas bien marcadas en la operaci√≥n de una CPU que son ‚Äòb√∫squeda‚Äô y ‚Äòejecuci√≥n‚Äô (*fetch* y *execute*). En la b√∫squeda se lee el c√≥digo de la operaci√≥n a ejecutar y se retiene en el registro de instrucci√≥n para que pueda ir siendo decodificado y se accionen las compuertas que habilitar√°n las varias partes del circuito. En el segundo se ejecuta esta instrucci√≥n y para ello se habilita el paso de los datos a ser procesados y, finalmente, se retiene el resultado final, cuando est√° estable, para que pueda disponerse de √©l.

En principio, el clock nos ofrece dos estados (0 y 1) por ciclo. En ocasiones, es necesario hilar m√°s fino y en lugar de operar en dos fases por ciclo, es necesario dar distintos tiempos a distintas operaciones. Para ello, el clock puede operar al doble de la velocidad y, tras dividirlo en dos, ofrecer 4 fases, (0, 1, 2 y 3) con cada latch y dem√°s componentes activ√°ndose en una o m√°s fases de esta secuencia. Lo que en m√∫sica dir√≠amos pasar del simple *um-pa* de la polca a la m√©trica m√°s compleja del tango, *um-pa-pa-pa*.

## Micro-c√≥digo

La CPU que hemos venido describiendo es extremadamente simple, pero no demasiado √∫til. Si quisi√©ramos agregarle m√°s habilidades, nos podr√≠amos encontrar con operaciones que no se pueden resolver en un solo ciclo. De hecho, sabemos que todas las operaciones que implican acceso a memoria externa requieren un par de ciclos, aunque en este caso, en el segundo ciclo no se hace nada, simplemente se espera. Tambi√©n hemos creado macro-instrucciones como `JF` o `SET` y otras m√°s que ya veremos, que requieren m√°s de una instrucci√≥n, o sea que realmente no pueden resolverse en un solo ciclo.

Acabamos de ver que muchos circuitos se pueden reducir a una sucesi√≥n de 3 tipos de compuertas con barras de se√±ales distribuyendo por todo el circuito los resultados de una etapa a las compuertas de la etapa siguiente. Alguien se podr√° preguntar si no podr√≠a hacerse un circuito que tuviera estas tres etapas de compuertas y sus barras de distribuci√≥n ya grabadas en el silicio del chip y se pudieran programar las conexiones. Eso, obviamente, ya existe y se llama PLA (*Programmable Logic Array*) y, como se puede ver en el diagrama en [Wikipedia](https://commons.wikimedia.org/wiki/File:Programmable_logic_array_(schematic_drawing_example).svg), su estructura interna se corresponde a lo ya descrito donde los c√≠rculos huecos en los cruces representan las conexiones que pueden programarse.

Eso se puede ver en circuitos reales como [esta imagen](https://en.wikipedia.org/wiki/MOS_Technology_6502#/media/File:BreakNES_MOS_6502.jpg) de una CPU de 8 bits, el MOS 6502 que es el chip que usaron varios de los primeros ordenadores hogare√±os como la Apple ][, Commodore 64 o tantos otros de aquella √©poca. Haciendo zoom en la parte superior, se llegan a ver los puntos de conexi√≥n que conectan juegos de barras. La t√©cnica no es nueva, en [esta imagen](https://www.computerhistory.org/revolution/mainframe-computers/7/164/582) podemos ver una tarjeta de micro-c√≥digo de una IBM 360 que es un ordenador que antecede a los circuitos integrados y donde el micro-c√≥digo es una serie de tarjetas Hollerith en pl√°stico (aislante) con trazas de aluminio donde las intersecciones que no se quieren se perforan con una [perforadora de tarjetas](https://es.wikipedia.org/wiki/Perforadora_de_tarjetas#/media/Archivo:IBM_card_punch_029.JPG) que, en aquella √©poca, cualquier centro de c√≥mputos ten√≠a.

Otro tipo de chip que se presta a esto es una memoria de lectura-solamente o ROM (*Read-Only Memory*) en cualquiera de sus variantes (PROM, EPROM, EEROM, etc). Si pensamos en sus l√≠neas de direcci√≥n como entradas y las de dato como salidas, una ROM nos puede ofrecer en sus salidas cualquier posible combinaci√≥n l√≥gica de sus entradas. No parece obvio y no es el uso habitual, pero si vemos el caso de la vieja tarjeta de micro-c√≥digo de la IBM-360, acaso no es una tarjeta de datos Hollerith tradicional, pero en lugar de ser de papel y leerse por transparencia, se lee el√©ctricamente. Una ROM es lo mismo que una colecci√≥n de estas tarjetas, como lo era el micro-c√≥digo de la IBM-360, que era un bastidor conteniendo docenas de estas tarjetas (una para cada c√≥digo de instrucci√≥n).

A diferencia del uso habitual de una memoria ROM que tiene muchos pines de entrada (16 para una memoria de 64k de profundidad) y pocos de salida (8 para una memoria de 8 bits de ancho de palabra) las memorias de micro-c√≥digo son m√°s anchas que profundas con menos pines de entrada que de salida. En el caso de nuestro set de instrucciones, tendr√≠a solamente 3 bits de entrada pero bastantes m√°s de salida, para accionar las varias partes del circuito.

¬øQu√© pasa si le ponemos m√°s micro-c√≥digo y hacemos un chip CISC con instrucciones m√°s complejas? Eso nos permitir√≠a, por ejemplo, condensar en un s√≥lo c√≥digo de operaci√≥n algunas de las macros que mencionamos arriba. Obviamente, en el set de instrucciones en la tabla de m√°s arriba, no hay huecos donde meter m√°s instrucciones, todas las posibles combinaciones de bits est√°n tomadas, pero ya estar√≠amos hablando de otra CPU con otro set de instrucciones, que por el momento no analizaremos.

Utilizaremos una ROM donde cada direcci√≥n de memoria corresponder√° con un paso de la micro-instrucci√≥n. La direcci√≥n de cada micro-instrucci√≥n la compondremos con la parte del c√≥digo que representa la operaci√≥n a ejecutar, no sus argumentos, que en el caso de nuestro viejo set de instrucciones ser√≠an 3 bits pero que, como debemos ampliar, dado que no tenemos huecos libres, le asignaremos 4 bits.

Para identificar el paso concreto dentro de la secuencia de micro-instrucciones, agregamos internamente un micro-contador de micro-instrucci√≥n. Para ello tenemos que ver cu√°ntos pasos requiere la secuencia m√°s larga de micro-instrucciones. Digamos que la secuencia de micro-instrucciones m√°s larga es de 5, que tenemos que redondear a la potencia de 2 siguiente, esto es 8, que implica 3 bits que debemos sumar a los 4 bits anteriores.

Finalmente, debemos prever nuestro clock. ¬øSer√° del tipo polca (*um-pa*) o tango (*um-pa-pa-pa*)? Si fuera este √∫ltimo, debemos agregar dos bits m√°s.

Entonces, nuestra ROM deber√° tener 9 bits de profundidad que representa 512 palabras de memoria.

Eso nos permite que el micro-c√≥digo ejecute para cada c√≥digo de (macro-)operaci√≥n, (en nuestro ejemplo previo de macro-instrucciones, digamos `JF`) una secuencia de micro-instrucciones (`NOT` y `JT`) en las fases del clock que correspondan.

Esto nos dice la profundidad de la ROM, no nos dice el ancho de palabra. Habitualmente, siendo que las ROM las usamos para datos, solemos tener 8, 16 o hasta 32 bits de ancho de palabra. Ac√° no estamos pensando en datos sino en controlar compuertas dentro de nuestra CPU, entonces, la cantidad de bits de salida depender√° de cu√°ntas se√±ales necesitemos para controlar cada una de esas compuertas. En nuestro ejemplo original, nada m√°s que en la ALU necesit√°bamos 4 bits para activar una de cuatro posibles salidas. Luego tenemos que agregar los latches que retienen los datos, los selectores de registros o de memoria y una larga lista de etc√©teras que, sin un dise√±o concreto, no podemos precisar.

A esto le tenemos que sumar un bit extra para se√±alar el fin de una micro-secuencia. Como las micro-secuencias tienen distinta cantidad de pasos, debemos saber cu√°ndo una secuencia est√° completa para pasar as√≠ a la siguiente macro-instrucci√≥n. Cuando el bit de fin de micro-secuencia est√° activo, el contador de paso de la micro-secuencia vuelve a cero y se lee la siguiente macro-instrucci√≥n.

## Subrutinas

Una subrutina es un segmento de c√≥digo que ejecuta una funcionalidad gen√©rica. ¬øQu√© se necesita para llamar una subrutina y volver de ella? B√°sicamente, guardar el contador de paso de programa, el `PC`, en una pila o *stack* y recuperarlo al volver.

A nuestro set de instrucciones (que como lo dejamos la √∫ltima vez no tiene huecos libres pero, siendo un ejercicio, podemos inventar otro set) tenemos que agregar dos instrucciones m√°s:

* `CALL mmmmmmmm` para llamar una subrutina que comienza en la instrucci√≥n de memoria que se indica
* `RET` para retornar de ella.

Ya tenemos una instrucci√≥n `JMP mmmmmmmm` que pasa a ejecutar la instrucci√≥n en la direcci√≥n que se indica, esto es, carga `mmmmmmmm` en el contador de paso de programa `PC`. La diferencia con hacer un `CALL` es que primero tenemos que guardar el `PC` actual en un stack antes de cargar la nueva direcci√≥n. Para ello necesitamos el micro-c√≥digo, dado que estamos hablando de dos operaciones internas separadas.

En una CPU normal de m√∫ltiples bits de ancho de palabra, con memoria RAM suficiente, la pila o *stack* suele ser un bloque de memoria asignado por el sistema operativo en la misma memoria principal donde se guarda tanto el programa como los datos. La CPU simplemente necesita incorporar lo que se llama un puntero al tope de la pila habitualmente abreviado como `SP` (por *stack pointer*).

En una CPU como la nuestra, que tiene un solo bit de ancho de palabra, para hacer un stack necesitamos alg√∫n tipo de memoria RAM, en este caso de 8 bits de ancho de palabra, y un contador como el [74x191](https://www.ti.com/lit/ds/symlink/cy74fct191t.pdf) que tiene 4 bits y se puede encadenar con otros (el pin marcado RC para llevar el ‚Äòresto‚Äô *carry*) para dar 8, 12, 16 o m√°s bits de conteo.

De hecho, el contador de paso de programa `PC` en nuestra CPU podr√≠a hacerse con dos de estos chips [74x191](https://www.ti.com/lit/ds/symlink/cy74fct191t.pdf) encadenados para poder contar con 8 bits, que es nuestro ancho de palabra de direcciones de programa. Se puede apreciar que el chip tiene tanto pines de entrada como de salida. Son estos pines de entrada los que, en el caso de un `JMP` o un `CALL`, cargan el `PC` con el nuevo valor mientras el pin marcado `CP` recibe el clock para ir avanzando la cuenta.

Lo importante para el `CALL` y `RET` es el `up/down`. El chip tiene un pin marcado `U/D` (por *Up/Down*) que le permite contar para arriba o para abajo. Entonces, cuando se hace un `CALL`, se incrementa el puntero al tope de la pila `SP` para que apunte a la siguiente posici√≥n disponible y se guarda el `PC` actual en esa casilla. Cuando se hace un `RET`, se carga el `PC` con el valor al tope de la pila y se decrementa el `SP` para que apunte al valor al tope del resto de la pila. Es importante que la secuencia entre acceder (en lectura y escritura) y el incremento/decremento del `SP` sea a la inversa en el `CALL` y el `RET` pues una operaci√≥n revierte la otra y deben ejecutarse en la secuencia inversa la una de la otra. Es indistinto si la pila crece hacia valores m√°s altos o si crece hacia abajo, basta ser consistente.

¬øC√≥mo se pasan par√°metros en las subrutinas? Usualmente, en sistemas chicos, como es el descrito, se designan registros internos para pasar los valores sobre los que la subrutina ha de operar. En sistemas m√°s complejos, los par√°metros se pasan en memoria, frecuentemente en la misma pila en que se guarda el stack de ejecuci√≥n. Para ello existen instrucciones, habitualmente denominadas `PUSH` y `POP`, que impl√≠citamente usan el puntero al tope de la pila, `SP` para acceder a la memoria.

* `PUSH rrrr` Se incrementa el `SP` para que apunte a la pr√≥xima posici√≥n disponible en la pila y se guarda el valor del registro `rrrr` en ella.
* `POP rrrr` Se lee el valor al tope de la pila para llevarlo llevarlo al registro `rrrr` y se decrementa el `SP`.

Suele ser responsabilidad del programador o del compilador retirar de la pila (`POP`) tantos datos como se hubieran guardado (`PUSH`) para que el `RET` encuentre el valor del `PC` guardado y no confunda un dato con c√≥digo.

Existen procesadores donde el `PC` y el `SP` son parte de los registros internos tal como lo son el `ACC` (registro 0) o el `ZERO` (registro 15). En ellos, puede no existir `CALL` y `RET` dado que se pueden reemplazar por macros:

```asm
    DEF PC 14  ; supongamos que el PC es el registro 14
    
    MACRO CALL m  ; defino la macro CALL con un argumento m
    PUSH PC  ; guardo el contador de paso de programa en la pila
    JMP m    ; voy a ejecutar el c√≥digo en la direcci√≥n m
    ENDMACRO

    MACRO RET  ; defino la macro RET que no lleva argumentos
    POP PC
    ENDMACRO
```

Esto, en definitiva, es lo que termina haciendo el micro-c√≥digo si `CALL` y `RET` formaran parte del set de instrucciones.

## Huecos en el set de instrucciones

Ya hemos visto que nuestro primer set de instrucciones est√° completo, para agregar cualquier otra capacidad interna al chip, o sea, que no sea a trav√©s de macros en el ensamblador, tenemos que ampliar el set de instrucciones. En lugar de los 3 bits originales (m√°s operandos) tendr√≠amos que pasar a 4, 5 o m√°s.

Dado que s√≥lo podemos hacerlo en potencias de 2, cada nueva ampliaci√≥n nos ofrece todo un abanico de posibles c√≥digos de instrucci√≥n. ¬øPodremos usarlas todas como hemos hecho con nuestro primer set de instrucciones? Y si no podemos usar todas las posibles combinaciones de bits de nuestro set ampliado, ¬øqu√© pasa con los huecos?

Hay varias posibilidades. La m√°s simple es no hacer nada. Si alguien incluyera en su programa el patr√≥n de bits de estos huecos, el resultado podr√≠a ser indeterminado e imprevisible.

La segunda opci√≥n es que todo hueco sea un `NOOP`, una abreviatura corriente para una instrucci√≥n que no hace nada (del ingl√©s *NO-OPeration*). Dado que ning√∫n ensamblador o compilador podr√≠a producir uno de estos c√≥digos, si el programa, en ejecuci√≥n, se encuentra una de estas instrucciones, lo m√°s probable es que el c√≥digo est√© corrupto, que el programa haya encontrado con una posici√≥n de datos en lugar de c√≥digo, que casualmente contenga uno de estos c√≥digos. Por ejemplo, si al llamar una subrutina los PUSHs y POPs para los argumentos no est√©n apareados como corresponde. En este caso, el programa est√° perdido de todas formas, su `PC` est√° apuntando a memoria de datos en lugar de c√≥digo y, por lo tanto, aunque esta instrucci√≥n NOOP no haga nada, el resto de lo que el chip ahora cree que es el programa tampoco tendr√° sentido.

La mejor opci√≥n es tratar el c√≥digo en esos huecos como una llamada a una subrutina, un `CALL`, a una posici√≥n pre-determinada. La ventaja de esto es que podemos escribir c√≥digo que responda a esta instrucci√≥n y decidir qu√© hacer, por ejemplo, reiniciar el chip desde cero. Otra posibilidad es aprovechar esa subrutina para ampliar, experimentalmente, el set de instrucciones del procesador. Esto es m√°s habitual de lo que podr√≠a suponerse. Hay familias de chips que tienen todos el mismo set de instrucciones base, pero algunos miembros de esa familia tienen extensiones al set de instrucciones b√°sico, por ejemplo, para hacer aritm√©tica de punto flotante, y otros chips no. Es lo que ocurre con el [set de instrucciones del RISC-V](https://es.wikipedia.org/wiki/RISC-V#ISA_Base_y_extensiones) que tiene su base y varias posibles extensiones ya establecidas.

¬øQu√© pasa si usamos una instrucci√≥n del set de aritm√©tica de punto flotante en un chip que no tiene esa extensi√≥n? Se puede cargar un emulador en software de estas operaciones de punto flotante y ejecutar el mismo programa que usa esas operaciones sin que el programa se entere que, en realidad, est√°n siendo simuladas. Se ejecutar√°n m√°s lento, pero el programa funcionar√°.

Y como el chip, al encontrar la instrucci√≥n inexistente, ha hecho un `CALL` esta subrutina puede retomar la ejecuci√≥n del programa inicial con un simple `RET`, como cualquier otra subrutina.

## Turing y Von Neuman

Si bien la descrita es una m√°quina de Turing (limitada, porque no tiene una cinta infinita, ni de lejos) no responde a una arquitectura de Von Neuman. ¬øPor qu√©? El gran concepto de Von Neuman fue tratar los programas como datos y usar la misma memoria tanto para el programa como para la informaci√≥n a procesar. Esto permite hacer cosas como un compilador o un int√©rprete que trata un programa como datos y es fundamental para LISP y otros programas de inteligencia artificial de la misma familia que modifican su c√≥digo mientras se ejecutan. En la pr√°ctica el uso m√°s frecuente de esta capacidad est√° en poder cargar un programa desde un dispositivo de almacenamiento como si fuera datos y luego ejecutarlo en ese mismo espacio de memoria.

La que hemos descrito hasta ahora claramente no es una m√°quina de Von Neuman. El ancho de palabra de los c√≥digos de ejecuci√≥n del set de instrucciones que vimos es de 11 bits mientas que los datos son de a 1 bit. Hemos designado 8 bits tanto para direcciones de memoria de programa como de memoria de datos pero esto ha sido, m√°s que nada, para realzar la regularidad del set de instrucciones, no porque sea necesario. Podr√≠amos hacer diferente la cantidad de bits de direcciones para `LOAD` y `SAVE` que para `JMP`, `JT` y `CALL`. Hasta donde hemos llegado, conceptualmente, son opciones v√°lidas.

No es inusual que los micro-controladores no sean m√°quinas de Von Neuman. Tiene sentido que no lo sean porque raramente van a ejecutar un programa distinto al que llevan grabado de f√°brica, programa que se graba por un mecanismo distinto de aquel en que lo ejecutan. Incluso el tipo de memoria es distinta para una y otra, ROM o EPROM o FLASH para programa, RAM para datos. La compilaci√≥n del programa de un micro-controlador habitualmente se hace en otra m√°quina, como en el caso del Arduino, donde el c√≥digo fuente en C se compila en la PC donde se carga el soft de desarrollo.

En una m√°quina de arquitectura de Von Neuman en la que los c√≥digos del programa y los datos residen en la misma memoria y se acceden por los mismos buses de datos y direcciones, debemos reservar momentos distintos del ciclo de ejecuci√≥n para acceder unos y otros.

En una m√°quina de Von Neuman, cuando nos encontramos con un `LOAD` o `SAVE` no podemos leer la siguiente instrucci√≥n inmediatamente pues debemos esperar que el dato que se carga o guarda se transita por el mismo bus de datos antes de ocuparlo leyendo la siguiente instrucci√≥n.

Al no ser una m√°quina de Von Neuman, podemos leer los c√≥digos de operaci√≥n del programa de forma continuada pues estos transitan por sus buses independientes de los datos.

## Reset

Se debe prever circuiter√≠a para el reset de la CPU, concretamente, cargar el `PC` con 0 (o cualquier valor predeterminado) y limpiar los latches que fuera necesario. Algunos cargan el `SP` con alg√∫n valor fijo.

Algunos procesadores de uso general (o sea, de Von Neuman) cargan el `PC` con el valor grabado en una cierta posici√≥n de memoria. Es costumbre utilizar las direcciones bajas de la memoria para RAM que, obviamente, contendr√° basura al arrancar. La ROM (por ejemplo el BIOS) suele ponerse en direcciones altas, por ello, al resetear es normal ir a buscar la direcci√≥n de inicio en esas posiciones altas donde est√° la ROM. Esta direcci√≥n, a su vez, usualmente apuntar√° tambi√©n al inicio del programa en esa misma ROM. En ordenadores m√°s antiguos, las llaves y pulsadores que se ve√≠an en los paneles de control eran para indicar la direcci√≥n de inicio del c√≥digo (entre otras cosas)

Ning√∫n procesador borra la memoria principal ni los registros, estos deben inicializarse expresamente.

‚Äî ‚Äî ‚Äî ‚Äî ‚Äî ‚Äî

Conceptualmente creo que esto cubre todo lo fundamental en el dise√±o de una CPU. Faltar√≠an:

* anchos de palabra mayores
* operaciones aritm√©ticas
* interrupciones (`CALL`s disparados por se√±ales de hardware, importante para responder r√°pidamente a sucesos externos)
* acceso a memoria indexado por registros internos por ejemplo, para acceder a sucesivos elementos de un array cuya base est√° guardada en un registro interno, o al segundo par√°metro de una subrutina, que est√° guardada en el stack y por ello est√° indexado relativo al `SP`.

Pero estos no hacen a lo fundamental de una CPU.